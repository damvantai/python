{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch.autograd as autograd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7efcfc904918>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_to_ix = {\"hello\": 0, \"world\": 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embeds = nn.Embedding(2, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding(2, 5)\n"
     ]
    }
   ],
   "source": [
    "print(embeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lookup_tensor = torch.LongTensor([word_to_ix[\"hello\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hello_embed = embeds(autograd.Variable(lookup_tensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      "-2.9718  1.7070 -0.4305 -2.2820  0.5237\n",
      "[torch.FloatTensor of size 1x5]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(hello_embed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CONTEXT_SIZE = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_sentence = \"\"\"When forty winters shall besiege thy brow,\n",
    "And dig deep trenches in thy beauty's field,\n",
    "Thy youth's proud livery so gazed on now,\n",
    "Will be a totter'd weed of small worth held:\n",
    "Then being asked, where all thy beauty lies,\n",
    "Where all the treasure of thy lusty days;\n",
    "To say, within thine own deep sunken eyes,\n",
    "Were an all-eating shame, and thriftless praise.\n",
    "How much more praise deserv'd thy beauty's use,\n",
    "If thou couldst answer 'This fair child of mine\n",
    "Shall sum my count, and make my old excuse,'\n",
    "Proving his beauty by succession thine!\n",
    "This were to be new made when thou art old,\n",
    "And see thy blood warm when thou feel'st it cold.\"\"\".split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['When', 'forty', 'winters', 'shall', 'besiege', 'thy', 'brow,', 'And', 'dig', 'deep', 'trenches', 'in', 'thy', \"beauty's\", 'field,', 'Thy', \"youth's\", 'proud', 'livery', 'so', 'gazed', 'on', 'now,', 'Will', 'be', 'a', \"totter'd\", 'weed', 'of', 'small', 'worth', 'held:', 'Then', 'being', 'asked,', 'where', 'all', 'thy', 'beauty', 'lies,', 'Where', 'all', 'the', 'treasure', 'of', 'thy', 'lusty', 'days;', 'To', 'say,', 'within', 'thine', 'own', 'deep', 'sunken', 'eyes,', 'Were', 'an', 'all-eating', 'shame,', 'and', 'thriftless', 'praise.', 'How', 'much', 'more', 'praise', \"deserv'd\", 'thy', \"beauty's\", 'use,', 'If', 'thou', 'couldst', 'answer', \"'This\", 'fair', 'child', 'of', 'mine', 'Shall', 'sum', 'my', 'count,', 'and', 'make', 'my', 'old', \"excuse,'\", 'Proving', 'his', 'beauty', 'by', 'succession', 'thine!', 'This', 'were', 'to', 'be', 'new', 'made', 'when', 'thou', 'art', 'old,', 'And', 'see', 'thy', 'blood', 'warm', 'when', 'thou', \"feel'st\", 'it', 'cold.']\n"
     ]
    }
   ],
   "source": [
    "print(test_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "115\n"
     ]
    }
   ],
   "source": [
    "print(len(test_sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trigrams = [([test_sentence[i], test_sentence[i + 1]], test_sentence[i + 2]) for i in range(len(test_sentence) - 2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(['When', 'forty'], 'winters'), (['forty', 'winters'], 'shall'), (['winters', 'shall'], 'besiege')]\n"
     ]
    }
   ],
   "source": [
    "print(trigrams[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab = set(test_sentence)\n",
    "word_to_ix ={word: i for i, word in enumerate(vocab)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'succession', 'beauty', 'Where', 'This', 'sunken', 'own', 'thriftless', 'asked,', 'lies,', 'it', 'see', 'forty', 'answer', 'winters', 'an', 'in', 'eyes,', 'where', 'lusty', 'praise.', 'days;', 'cold.', \"'This\", 'shame,', 'art', 'a', 'proud', 'worth', 'Will', 'count,', 'praise', \"deserv'd\", 'of', 'When', 'Shall', 'thy', 'deep', \"beauty's\", 'being', 'Thy', 'couldst', 'Then', 'small', 'when', 'besiege', 'the', 'by', 'to', 'were', 'fair', 'dig', 'If', 'livery', 'on', 'thou', 'trenches', 'gazed', 'And', 'now,', 'brow,', 'use,', 'and', 'much', \"totter'd\", 'blood', 'mine', 'How', 'Were', 'say,', 'old,', \"youth's\", 'child', 'his', \"feel'st\", 'treasure', 'old', 'field,', 'so', 'within', 'thine', 'held:', 'sum', 'all-eating', 'shall', 'thine!', 'warm', 'my', 'all', \"excuse,'\", 'be', 'new', 'weed', 'more', 'Proving', 'made', 'make', 'To'}\n"
     ]
    }
   ],
   "source": [
    "print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'own': 5, 'succession': 0, 'the': 45, 'beauty': 1, 'Where': 2, 'were': 48, 'more': 92, 'This': 3, 'sunken': 4, 'dig': 50, 'If': 51, 'livery': 52, 'on': 53, 'thou': 54, 'thriftless': 6, 'trenches': 55, 'asked,': 7, 'lies,': 8, 'And': 57, 'gazed': 56, 'it': 9, 'by': 46, 'see': 10, 'now,': 58, 'forty': 11, 'answer': 12, 'much': 62, 'How': 66, 'winters': 13, 'brow,': 59, 'in': 15, 'old,': 69, 'so': 77, 'say,': 68, 'eyes,': 16, 'couldst': 40, 'and': 61, 'where': 17, 'a': 25, 'lusty': 18, 'praise.': 19, 'to': 47, \"youth's\": 70, 'days;': 20, 'shall': 83, \"totter'd\": 63, 'blood': 64, \"'This\": 22, 'mine': 65, 'warm': 85, 'shame,': 23, 'art': 24, 'Were': 67, \"feel'st\": 73, 'his': 72, 'child': 71, 'proud': 26, 'treasure': 74, 'old': 75, 'worth': 27, 'cold.': 21, 'field,': 76, 'within': 78, 'held:': 80, 'sum': 81, 'Will': 28, 'count,': 29, 'fair': 49, 'praise': 30, 'all-eating': 82, \"deserv'd\": 31, 'thine!': 84, 'of': 32, 'thine': 79, 'When': 33, 'my': 86, 'Shall': 34, 'thy': 35, 'deep': 36, \"beauty's\": 37, 'being': 38, 'Thy': 39, 'all': 87, \"excuse,'\": 88, 'be': 89, 'new': 90, 'weed': 91, 'an': 14, 'Then': 41, 'Proving': 93, 'small': 42, 'made': 94, 'when': 43, 'besiege': 44, 'make': 95, 'To': 96, 'use,': 60}\n",
      "97\n"
     ]
    }
   ],
   "source": [
    "print(word_to_ix)\n",
    "print(len(word_to_ix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n"
     ]
    }
   ],
   "source": [
    "for i, word in enumerate(vocab):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class NGramLanguageModeler(nn.Module):\n",
    "    \n",
    "    def __init__(self, vocab_size, embedding_dim, context_size):\n",
    "        super(NGramLanguageModeler, self).__init__()\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.linear1 = nn.Linear(context_size * embedding_dim, 128)\n",
    "        self.linear2 = nn.Linear(128, vocab_size)\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        embeds = self.embeddings(inputs).view((1, -1))\n",
    "        out = F.relu(self.linear1(embeds))\n",
    "        out = self.linear2(out)\n",
    "        log_probs = F.log_softmax(out)\n",
    "        return log_probs\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss_function = nn.NLLLoss()\n",
    "model = NGramLanguageModeler(len(vocab), EMBEDDING_DIM, CONTEXT_SIZE)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      " 521.3672\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 519.0223\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 516.6968\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 514.3903\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 512.0995\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 509.8223\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 507.5590\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 505.3079\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 503.0688\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 500.8437\n",
      "[torch.FloatTensor of size 1]\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10):\n",
    "    total_loss = torch.Tensor([0])\n",
    "    for context, target in trigrams:\n",
    "        \n",
    "        context_idxs = [word_to_ix[w] for w in context]\n",
    "        context_var = autograd.Variable(torch.LongTensor(context_idxs))\n",
    "        \n",
    "        model.zero_grad()\n",
    "        \n",
    "        log_probs = model(context_var)\n",
    "        \n",
    "#         loss = loss_function(log_probs, autograd.Variable(torch.LongTensor[word_to_ix[target]]))\n",
    "        loss = loss_function(log_probs, autograd.Variable(torch.LongTensor([word_to_ix[target]])))    \n",
    "    \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.data\n",
    "    losses.append(total_loss)\n",
    "print(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CONTEXT_SIZE = 2\n",
    "raw_text = \"\"\"We are about to study the idea of a computational process.\n",
    "Computational processes are abstract beings that inhabit computers.\n",
    "As they evolve, processes manipulate other abstract things called data.\n",
    "The evolution of a process is directed by a pattern of rules\n",
    "called a program. People create programs to direct processes. In effect,\n",
    "we conjure the spirits of the computer with our spells.\"\"\".split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = set(raw_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'As',\n",
       " 'Computational',\n",
       " 'In',\n",
       " 'People',\n",
       " 'The',\n",
       " 'We',\n",
       " 'a',\n",
       " 'about',\n",
       " 'abstract',\n",
       " 'are',\n",
       " 'beings',\n",
       " 'by',\n",
       " 'called',\n",
       " 'computational',\n",
       " 'computer',\n",
       " 'computers.',\n",
       " 'conjure',\n",
       " 'create',\n",
       " 'data.',\n",
       " 'direct',\n",
       " 'directed',\n",
       " 'effect,',\n",
       " 'evolution',\n",
       " 'evolve,',\n",
       " 'idea',\n",
       " 'inhabit',\n",
       " 'is',\n",
       " 'manipulate',\n",
       " 'of',\n",
       " 'other',\n",
       " 'our',\n",
       " 'pattern',\n",
       " 'process',\n",
       " 'process.',\n",
       " 'processes',\n",
       " 'processes.',\n",
       " 'program.',\n",
       " 'programs',\n",
       " 'rules',\n",
       " 'spells.',\n",
       " 'spirits',\n",
       " 'study',\n",
       " 'that',\n",
       " 'the',\n",
       " 'they',\n",
       " 'things',\n",
       " 'to',\n",
       " 'we',\n",
       " 'with'}"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(vocab)\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'evolution': 0, 'conjure': 1, 'manipulate': 2, 'In': 3, 'spirits': 31, 'evolve,': 4, 'directed': 5, 'the': 6, 'a': 7, 'to': 8, 'we': 10, 'programs': 11, 'process': 12, 'rules': 13, 'inhabit': 15, 'things': 16, 'computational': 17, 'program.': 18, 'computer': 19, 'We': 20, 'idea': 21, 'study': 22, 'our': 23, 'The': 24, 'they': 25, 'effect,': 26, 'are': 27, 'processes': 39, 'processes.': 14, 'computers.': 29, 'pattern': 30, 'process.': 32, 'People': 33, 'Computational': 34, 'spells.': 35, 'is': 36, 'As': 37, 'abstract': 38, 'direct': 40, 'that': 41, 'other': 43, 'beings': 42, 'by': 9, 'data.': 44, 'about': 45, 'of': 28, 'called': 46, 'with': 47, 'create': 48}\n",
      "62\n"
     ]
    }
   ],
   "source": [
    "word_to_ix = {word:i for i, word in enumerate(vocab)}\n",
    "data = []\n",
    "print(word_to_ix)\n",
    "print(len(raw_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(['We', 'are', 'to', 'study'], 'about'), (['are', 'about', 'study', 'the'], 'to'), (['about', 'to', 'the', 'idea'], 'study'), (['to', 'study', 'idea', 'of'], 'the'), (['study', 'the', 'of', 'a'], 'idea')]\n"
     ]
    }
   ],
   "source": [
    "for i in range(2, len(raw_text) - 2):\n",
    "    context = [raw_text[i - 2], raw_text[i - 1], raw_text[i + 1], raw_text[i + 2]]\n",
    "    target = raw_text[i]\n",
    "    data.append((context, target))\n",
    "print(data[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class CBOW(nn.Module):\n",
    "\n",
    "#     def __init__(self, vocab_size, embedding_dim, context_size):\n",
    "#         super(CBOW, self).__init__()\n",
    "#         self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "#         self.linear1 = nn.Linear(context_size * embedding_dim, 128)\n",
    "#         self.linear2 = nn.Linear(128, vocab_size)\n",
    "        \n",
    "#     def forward(self, inputs):\n",
    "#         embeds = self.embeddings(inputs).view((1, -1))\n",
    "#         out = F.relu(self.linear1(embeds))\n",
    "#         out = self.linear2(out)\n",
    "#         log_probs = F.log_softmax(out)\n",
    "#         return log_probs\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def make_context_vector(context, word_to_ix):\n",
    "#     idxs = [word_to_ix[w] for w in context]\n",
    "#     tensor = torch.LongTensor(idxs)\n",
    "#     return autograd.Variable(tensor)\n",
    "\n",
    "# make_context_vector(data[0][0], word_to_ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# emirceyani code cbow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CBOW(nn.Module):\n",
    "    \n",
    "    def __init__(self, vocab_size, embedding_dim, context_size):\n",
    "        super(CBOW, self).__init__()\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.linear1 = nn.Linear(embedding_dim, vocab_size)\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        embeds = self.embeddings(inputs).sum(dim=0).view((1, -1))\n",
    "        out = self.linear1(embeds)\n",
    "        log_probs = F.log_softmax(out)\n",
    "        return log_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_context_vector(context, word_to_ix):\n",
    "    idxs = [word_to_ix[w] for w in context]\n",
    "    tensor = torch.LongTensor(idxs)\n",
    "    return autograd.Variable(tensor)\n",
    "\n",
    "context = make_context_vector(data[0][0], word_to_ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create your model and train. here are some functions to help you make\n",
    "# the data ready for use by your module\n",
    "losses = []\n",
    "loss_function = nn.NLLLoss()\n",
    "model = CBOW(vocab_size, EMBEDDING_DIM, CONTEXT_SIZE)\n",
    "optimizer = optim.SGD(model.parameters(), lr = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(200):\n",
    "    total_loss = torch.Tensor([0])\n",
    "    for context, target in data:\n",
    "        \n",
    "        # step 1: prepare the inputs to be passed to the model\n",
    "        # into integer indices and wrap them in variables\n",
    "        context_idxs = [word_to_ix[w] for w in context]\n",
    "        context_var = autograd.Variable(torch.LongTensor(context_idxs))\n",
    "        \n",
    "        # step 2: \n",
    "        model.zero_grad()\n",
    "        \n",
    "        # step 3: run the forward pass\n",
    "        log_probs = model(context_var)\n",
    "        \n",
    "        # step 4: compute your loss function\n",
    "        loss = loss_function(log_probs, autograd.Variable(torch.LongTensor([word_to_ix[target]])))\n",
    "        \n",
    "        # step 5: do the backward pass and update the gradient\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.data\n",
    "    losses.append(total_loss)\n",
    "print(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "acc = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for context, target in data:\n",
    "    # step 1: prepare the inputs to be passed to the model\n",
    "    context_idxs = [word_to_ix[w] for w in context]\n",
    "    context_var = autograd.Variables(torch.LongTensor(context_idxs))\n",
    "    log_probs = model(context_var)\n",
    "    _, idx = torch.min(log_probs, -1)\n",
    "    print (context, word_to_ix[target], idx.data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
