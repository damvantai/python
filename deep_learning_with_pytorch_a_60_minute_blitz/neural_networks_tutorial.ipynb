{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # 1 input image channel, 6 output channels, 5x5 square convolution kernel\n",
    "        # kernel\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        # an affine operation: y = Wx + b\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Max pooling over a (2, 2) window\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        # If the size is a square you can only specify a single number\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net (\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear (400 -> 120)\n",
      "  (fc2): Linear (120 -> 84)\n",
      "  (fc3): Linear (84 -> 10)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "params = list(net.parameters())\n",
    "print(len(params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 1, 5, 5])\n"
     ]
    }
   ],
   "source": [
    "print(params[0].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6])\n"
     ]
    }
   ],
   "source": [
    "print(params[1].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 6, 5, 5])\n"
     ]
    }
   ],
   "source": [
    "print(params[2].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16])\n"
     ]
    }
   ],
   "source": [
    "print(params[3].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parameter containing:\n",
      "(0 ,0 ,.,.) = \n",
      "  0.1609  0.1418 -0.1929  0.1251 -0.0802\n",
      "  0.1654 -0.0955  0.1523 -0.1061  0.0423\n",
      " -0.1432 -0.1374  0.1380  0.1395  0.0986\n",
      "  0.0458  0.1220  0.0859 -0.0048  0.0316\n",
      " -0.1140 -0.0974 -0.0903 -0.0556 -0.0511\n",
      "\n",
      "(1 ,0 ,.,.) = \n",
      "  0.1725 -0.1697 -0.0894  0.1813  0.1547\n",
      "  0.1855  0.0730  0.0703 -0.0323  0.0834\n",
      "  0.0150  0.0016 -0.1991  0.1197  0.0476\n",
      "  0.0159 -0.0141 -0.1757 -0.1675 -0.1524\n",
      " -0.0825  0.1435 -0.0673 -0.1666 -0.1215\n",
      "\n",
      "(2 ,0 ,.,.) = \n",
      "  0.1541  0.1610 -0.1984 -0.1554 -0.0720\n",
      "  0.1876  0.0226 -0.0735  0.0470 -0.1477\n",
      " -0.1549  0.0237 -0.1148 -0.0905 -0.0915\n",
      "  0.0154 -0.0012  0.1601  0.1924 -0.0985\n",
      "  0.1723  0.1463  0.0097  0.0626 -0.1366\n",
      "\n",
      "(3 ,0 ,.,.) = \n",
      "  0.0739  0.1847 -0.1897 -0.0956 -0.1144\n",
      " -0.0122  0.1020  0.0556 -0.0621  0.1804\n",
      " -0.1098  0.1886  0.0845 -0.1349 -0.0125\n",
      " -0.0404 -0.1927  0.0899 -0.0285 -0.0791\n",
      " -0.0825 -0.1415  0.0044  0.0460  0.1105\n",
      "\n",
      "(4 ,0 ,.,.) = \n",
      "  0.0897  0.0964  0.1764 -0.1775  0.0839\n",
      "  0.1792 -0.0937 -0.1957 -0.1764 -0.1571\n",
      "  0.0203 -0.1834  0.1843 -0.0007 -0.1365\n",
      " -0.1089 -0.1682 -0.1910  0.0188  0.0233\n",
      " -0.1677 -0.1702 -0.1939  0.0949 -0.0562\n",
      "\n",
      "(5 ,0 ,.,.) = \n",
      " -0.0090  0.0697 -0.1962 -0.1301 -0.1403\n",
      "  0.0001 -0.0108  0.0113 -0.0493  0.1320\n",
      " -0.1547  0.1656 -0.1469 -0.1340 -0.0737\n",
      "  0.0976 -0.1540  0.1395  0.1550 -0.1435\n",
      "  0.1662 -0.1627 -0.0248 -0.0323 -0.1909\n",
      "[torch.FloatTensor of size 6x1x5x5]\n",
      ", Parameter containing:\n",
      "-0.1869\n",
      " 0.0254\n",
      " 0.1448\n",
      "-0.0834\n",
      "-0.0671\n",
      "-0.1614\n",
      "[torch.FloatTensor of size 6]\n",
      ", Parameter containing:\n",
      "(0 ,0 ,.,.) = \n",
      "1.00000e-02 *\n",
      "  3.8666  2.7819  7.9802  3.8997  3.0080\n",
      "  7.9267 -7.1914  0.2525  7.5958 -3.1188\n",
      " -3.5117  6.9707 -3.2402 -1.5778 -0.3814\n",
      "  3.9530 -7.3240  1.9868  7.6771 -4.2989\n",
      " -4.7155 -2.1894 -0.5551 -4.7987 -1.9964\n",
      "\n",
      "(0 ,1 ,.,.) = \n",
      "1.00000e-02 *\n",
      " -7.5170  6.1096  8.0568 -4.7451 -7.9729\n",
      "  0.4264  3.8958  2.9989 -6.5258  7.7391\n",
      " -7.1621 -4.8958 -6.4766  1.0422  7.6305\n",
      " -2.5870  1.4429  1.0238 -0.0034 -3.2801\n",
      "  5.1915  6.8470  0.2937  1.7994  7.5212\n",
      "\n",
      "(0 ,2 ,.,.) = \n",
      "1.00000e-02 *\n",
      "  3.8599  6.7857  4.8944  8.1257  4.8534\n",
      "  6.6293  1.4260 -0.0378 -2.6528 -6.8287\n",
      "  3.0444  4.4869  6.5264 -5.3251  0.2234\n",
      " -1.2196  4.3130 -3.4128 -1.5755  5.2090\n",
      " -5.2518 -3.7445  5.0868  7.9103  0.0901\n",
      "\n",
      "(0 ,3 ,.,.) = \n",
      "1.00000e-02 *\n",
      "  5.7252  3.2762 -6.0547  0.0345 -5.8459\n",
      "  5.1259  7.9485  2.0964  6.8764 -4.7386\n",
      "  6.0736 -4.5676  2.1735  2.9573 -5.7416\n",
      " -3.8557  2.9295  3.3934  2.1711 -0.7578\n",
      " -1.8903  7.2010 -6.5427  5.2773 -4.3055\n",
      "\n",
      "(0 ,4 ,.,.) = \n",
      "1.00000e-02 *\n",
      " -1.9226 -6.0287 -3.6135  7.5538  0.8724\n",
      "  4.2538 -2.2685 -1.9154 -6.5951 -4.1630\n",
      " -3.8875 -4.1103 -1.0249 -4.6564 -1.4741\n",
      " -5.6997  1.0306 -5.0008 -2.3860 -4.1505\n",
      " -3.1114 -4.6457  2.1959  4.2697  5.2125\n",
      "\n",
      "(0 ,5 ,.,.) = \n",
      "1.00000e-02 *\n",
      "  6.3484  7.4715 -0.9466  4.9226  6.0880\n",
      "  7.6900  5.9217 -7.2532 -7.6851 -0.9389\n",
      " -0.0091  3.6974 -8.1524  2.8854 -2.8590\n",
      " -2.1304  0.9986  5.4627  3.5641 -6.3515\n",
      " -7.8338 -5.1517  3.1128 -4.6273 -1.1952\n",
      "     ⋮ \n",
      "\n",
      "(1 ,0 ,.,.) = \n",
      "1.00000e-02 *\n",
      " -7.2821  2.6725 -0.4715 -5.2903 -5.7449\n",
      " -5.7031  5.2694 -0.3063  3.3845 -3.5840\n",
      "  0.2215 -3.9574 -6.6703  2.0669 -7.8602\n",
      " -7.3532 -4.3094  2.4633 -7.1735  1.4930\n",
      "  0.6133  0.2746  5.3387  5.5063  4.0905\n",
      "\n",
      "(1 ,1 ,.,.) = \n",
      "1.00000e-02 *\n",
      " -3.1640  8.0824 -8.0600  8.1262  5.0944\n",
      " -2.7748 -3.0269 -3.5146 -3.0948 -2.1543\n",
      " -3.5123  4.9164  6.6939 -0.7705  0.1725\n",
      "  0.6215  1.2511  2.9438  4.2662  4.0235\n",
      "  1.1952  2.2977 -6.6516  4.5965  8.0101\n",
      "\n",
      "(1 ,2 ,.,.) = \n",
      "1.00000e-02 *\n",
      " -2.1332 -6.0663  3.1069 -1.3689  3.9262\n",
      " -1.8568 -4.9176  0.8041  0.1966  7.3853\n",
      "  3.3295 -8.0432 -4.2324  0.6997 -3.9884\n",
      " -5.7506  0.9994 -4.8383  2.6032  3.7693\n",
      " -3.7023  0.9631 -6.6639 -1.9006 -0.4891\n",
      "\n",
      "(1 ,3 ,.,.) = \n",
      "1.00000e-02 *\n",
      " -0.1941 -7.9837 -6.3273 -2.4436  5.3128\n",
      " -0.3056 -2.7167  6.3653  7.8403  7.7059\n",
      "  5.0029  4.5906  6.6084  1.7606 -1.7008\n",
      " -1.5496 -2.4609 -7.8594 -3.6102 -1.8627\n",
      "  3.9667 -2.2896 -2.5970 -2.7852 -1.7690\n",
      "\n",
      "(1 ,4 ,.,.) = \n",
      "1.00000e-02 *\n",
      "  6.1816 -4.4012 -4.9821  2.2836  1.0651\n",
      "  2.7206 -3.4612 -3.7771 -4.9502 -0.7029\n",
      "  5.2537 -2.1349 -1.4486  0.6943 -4.6941\n",
      " -0.7483 -2.7599 -7.3944  2.9724  7.7521\n",
      " -5.0694  4.9040 -3.3458 -0.7297  2.2111\n",
      "\n",
      "(1 ,5 ,.,.) = \n",
      "1.00000e-02 *\n",
      " -7.7903 -4.0698  6.0996  5.7666 -6.0087\n",
      " -2.9917 -6.9059  7.1237 -2.5175 -6.3504\n",
      "  0.8843 -3.7014  1.8785  1.3269 -0.5292\n",
      " -5.0485 -4.0106  4.3804  7.9344 -6.7333\n",
      "  5.5321  3.0454 -6.4489 -5.1701  6.4084\n",
      "     ⋮ \n",
      "\n",
      "(2 ,0 ,.,.) = \n",
      "1.00000e-02 *\n",
      "  7.2542  7.5195  7.1944  3.4245  0.2345\n",
      " -1.5500 -5.6701 -5.9760  4.6812 -4.0568\n",
      "  7.8522  6.6193  7.3062  6.2946 -3.8599\n",
      " -4.5606 -3.1631 -5.2818  3.6636 -3.9088\n",
      "  2.0226  6.0848 -0.6200  7.0628 -4.3971\n",
      "\n",
      "(2 ,1 ,.,.) = \n",
      "1.00000e-02 *\n",
      "  5.2722  8.0797  7.9739  3.6160 -0.2560\n",
      "  6.7625  3.2950 -1.4720  1.3139 -3.5052\n",
      " -6.6906  5.5383  4.7632  4.0515  6.9187\n",
      " -5.0381  3.8424  1.7746 -4.0731 -3.5912\n",
      " -0.0534 -2.5731 -6.8479 -1.6493 -1.7918\n",
      "\n",
      "(2 ,2 ,.,.) = \n",
      "1.00000e-02 *\n",
      " -5.5523 -0.6395 -5.5772 -2.2914 -4.9025\n",
      " -7.2850  5.8115 -4.8181 -7.3565 -2.5958\n",
      " -6.4356 -6.0072 -4.0209 -8.1541  6.3810\n",
      "  6.0039  7.1022 -2.2218 -2.8854 -1.1329\n",
      "  7.5907 -3.9066  5.6603  5.7888  3.2546\n",
      "\n",
      "(2 ,3 ,.,.) = \n",
      "1.00000e-02 *\n",
      "  4.4500 -6.1464 -1.2281 -3.3042 -6.4026\n",
      " -5.8954  2.3061 -2.1855 -3.0033 -1.4325\n",
      "  0.1049  5.3370  7.7987  5.6634  4.0031\n",
      " -7.1514 -6.9853  3.7147  1.6760 -1.4162\n",
      " -3.7582 -2.3978 -0.1751  3.2549  5.1183\n",
      "\n",
      "(2 ,4 ,.,.) = \n",
      "1.00000e-02 *\n",
      "  5.0460 -7.9370 -0.5793  8.1644  3.0150\n",
      " -7.2352 -6.1137  4.1729  3.7782 -4.2533\n",
      " -7.5093 -2.1532 -3.5351  4.8234  5.1284\n",
      "  1.6584  2.0919 -7.9371  6.5590 -3.5572\n",
      " -5.3988  3.3797  1.8234 -0.2333 -1.4338\n",
      "\n",
      "(2 ,5 ,.,.) = \n",
      "1.00000e-02 *\n",
      " -1.1799 -4.2877 -4.5805 -6.6685  3.6253\n",
      "  7.9078 -6.8762  3.1206 -3.5036  1.5812\n",
      " -7.6442 -4.5015 -4.1025  3.6626  3.9189\n",
      " -0.0802  5.2829  3.9874 -0.0996 -5.0288\n",
      "  0.0445 -1.4971 -6.4819  5.4832  3.8963\n",
      "...   \n",
      "     ⋮ \n",
      "\n",
      "(13,0 ,.,.) = \n",
      "1.00000e-02 *\n",
      "  5.3034  6.4280  7.1243 -2.7735 -1.6288\n",
      "  5.7297 -6.3642  4.0853  5.6090 -7.4316\n",
      "  1.5132 -2.7850 -5.2397 -3.2253  6.3496\n",
      "  1.3206 -7.0923 -0.6954 -1.2581  2.9830\n",
      " -0.5257  7.3355 -6.6013  1.8951 -2.2689\n",
      "\n",
      "(13,1 ,.,.) = \n",
      "1.00000e-02 *\n",
      "  7.0305  3.7227 -3.1202 -6.0022  6.8837\n",
      "  0.7726  7.4625 -6.8719  0.4760  6.6060\n",
      " -6.0850  4.7098  4.9691 -4.3509 -5.2997\n",
      " -0.9569 -3.2652 -5.6533  2.4535 -4.5356\n",
      " -4.6061  6.9227 -6.1477 -3.1540  7.1787\n",
      "\n",
      "(13,2 ,.,.) = \n",
      "1.00000e-02 *\n",
      " -2.3585 -4.8271  6.7553  4.2950 -4.1309\n",
      " -3.9517 -7.4486 -7.5075 -4.1607  8.0526\n",
      " -3.2462 -4.5191 -6.1698 -5.0825  7.3910\n",
      " -2.3068 -6.5677  6.2044 -5.2469  3.7803\n",
      " -3.4487 -4.1300  3.9923  4.8095 -6.6887\n",
      "\n",
      "(13,3 ,.,.) = \n",
      "1.00000e-02 *\n",
      "  6.2370 -4.8742  2.4975  0.8739 -0.1266\n",
      "  6.6532 -7.2639  4.0083  8.1140  4.4463\n",
      " -5.2701 -7.5968  5.2389  6.6887 -2.8502\n",
      " -1.8671  4.3359 -5.3185 -5.5265 -4.4673\n",
      "  3.9487  1.2279  4.5314 -1.4164  5.3286\n",
      "\n",
      "(13,4 ,.,.) = \n",
      "1.00000e-02 *\n",
      " -2.5186 -2.2704 -6.8492 -1.6324 -3.1479\n",
      " -2.4131  4.1007 -0.5627 -0.7448  1.6977\n",
      "  3.0259 -3.3164 -4.0885 -1.2374  0.9766\n",
      " -0.6178  0.4360  6.4466 -6.5672 -2.7522\n",
      "  2.7193  7.3682  3.9537 -1.8395  3.2661\n",
      "\n",
      "(13,5 ,.,.) = \n",
      "1.00000e-02 *\n",
      "  5.2121  0.8280 -0.8214  5.9332 -7.0738\n",
      "  7.7581 -3.8956 -6.9869 -5.3249  5.4550\n",
      " -3.9086 -2.9119 -8.0872  2.9062 -3.1796\n",
      "  5.2719 -0.4254 -1.7958 -4.0032 -1.5653\n",
      "  3.6057 -2.3517  4.9972  0.1058  1.6158\n",
      "     ⋮ \n",
      "\n",
      "(14,0 ,.,.) = \n",
      "1.00000e-02 *\n",
      "  4.0049 -0.9713 -4.5315 -2.0630  2.1862\n",
      " -6.7594 -2.6267  3.8768  5.3029  4.5759\n",
      "  1.9315 -1.6415  2.9516 -6.1694  1.8463\n",
      "  1.7939 -5.5843  3.2790 -7.0582 -2.4407\n",
      "  8.1029 -0.7815  1.7232  7.4478  0.1741\n",
      "\n",
      "(14,1 ,.,.) = \n",
      "1.00000e-02 *\n",
      "  0.6473  1.5383 -4.0626  6.4574 -1.6666\n",
      " -1.2275 -7.6725  5.1098 -6.9510  4.9247\n",
      " -6.4464 -1.9842 -6.5842 -2.7670 -0.6605\n",
      " -0.6300  5.7741 -0.2819 -2.7874  5.2788\n",
      "  1.0390  0.6153  6.2046  7.8555  0.9427\n",
      "\n",
      "(14,2 ,.,.) = \n",
      "1.00000e-02 *\n",
      "  3.3563  6.1555 -1.0236 -4.5154 -3.9740\n",
      " -1.2476 -6.8784 -5.9080  1.0006  7.2540\n",
      "  0.5581  3.6882  5.0394 -2.1596 -5.6865\n",
      " -3.1763 -6.6736 -0.8371 -3.8050  6.1600\n",
      " -0.9082  0.0143 -3.3805  1.8450  5.9981\n",
      "\n",
      "(14,3 ,.,.) = \n",
      "1.00000e-02 *\n",
      " -2.7060  3.9060  5.3602 -6.8412  0.5719\n",
      " -1.9093 -4.2598  7.1755  5.4642 -4.2117\n",
      "  0.6684  0.6705  8.0565 -0.4599 -3.4687\n",
      " -0.8176  0.0782 -5.6837  7.8587 -2.5950\n",
      " -7.4773  2.2971  1.3839 -5.4643  5.6585\n",
      "\n",
      "(14,4 ,.,.) = \n",
      "1.00000e-02 *\n",
      " -3.5131 -3.1700  6.1838  2.3859 -4.9532\n",
      " -3.3179 -6.1306  4.1377  7.0838  6.3663\n",
      "  6.3929 -1.9179  5.1192  7.1215 -0.8371\n",
      " -7.0213  1.2517 -3.5556 -0.4829  6.2076\n",
      " -2.2600  5.4222 -5.5376 -1.3756  1.7272\n",
      "\n",
      "(14,5 ,.,.) = \n",
      "1.00000e-02 *\n",
      " -7.0189 -0.3008 -3.6112  3.9017 -7.0046\n",
      "  0.3514 -1.4546 -3.4790  5.9211  8.1122\n",
      "  2.5583 -3.1451  0.1038 -0.0643  6.9117\n",
      "  0.5395  4.0140  7.8812 -7.5760 -5.2979\n",
      " -5.8715 -2.6020  4.9088  4.9598  3.5495\n",
      "     ⋮ \n",
      "\n",
      "(15,0 ,.,.) = \n",
      "1.00000e-02 *\n",
      "  5.7106  3.5431  7.3303  6.2399  7.7586\n",
      " -5.0870 -3.1892 -0.3944  1.7362  1.0350\n",
      "  5.4772  7.6409  0.4679  2.6160  7.5016\n",
      "  6.1706  6.9073  3.2627  4.6622 -1.0867\n",
      "  7.0519 -7.6522 -4.3888 -0.8980 -7.3444\n",
      "\n",
      "(15,1 ,.,.) = \n",
      "1.00000e-02 *\n",
      " -7.4189 -6.6854  3.4612  6.2680  6.2978\n",
      "  2.1627 -0.8539 -7.4482  2.0876 -0.0546\n",
      " -7.5567 -0.2756 -0.5488 -3.6850  1.3997\n",
      "  4.5470  8.0697 -1.6504  4.0696 -6.3444\n",
      " -8.0795  4.5596  5.1633  2.2880 -4.9946\n",
      "\n",
      "(15,2 ,.,.) = \n",
      "1.00000e-02 *\n",
      "  3.1659  1.3051 -2.6923  1.2942  1.5091\n",
      " -5.5733 -1.6391 -1.1920  0.8275 -1.6923\n",
      " -7.7953  1.4920 -1.1915 -3.3853  3.7886\n",
      "  2.0249 -1.0569  3.1308  6.2908  3.9233\n",
      "  2.2363  0.3693 -3.5106  2.3590  4.8847\n",
      "\n",
      "(15,3 ,.,.) = \n",
      "1.00000e-02 *\n",
      " -5.1095 -0.2951  5.9832  3.6651  2.8414\n",
      "  3.2813 -3.5085  6.3202  2.7752 -1.5552\n",
      " -1.5517  6.8763  0.1866  7.9747 -7.8726\n",
      "  6.9096 -0.7256  4.7696 -3.5795 -6.8394\n",
      "  7.0450 -2.3688 -1.2959  5.3945 -3.2730\n",
      "\n",
      "(15,4 ,.,.) = \n",
      "1.00000e-02 *\n",
      "  6.8868  6.6703  5.6488 -2.0708 -3.0287\n",
      " -2.2063  5.0454  4.8422  6.1485  7.2861\n",
      " -1.7387  3.7079 -0.7811 -6.9450  6.6982\n",
      "  2.5220 -1.4279 -1.1428 -4.5690 -2.3734\n",
      "  0.1703 -0.3993  4.6606 -4.0775  3.7455\n",
      "\n",
      "(15,5 ,.,.) = \n",
      "1.00000e-02 *\n",
      " -2.1725 -7.2387  0.9321  6.2998  8.1071\n",
      "  5.7047  2.1846  3.4153 -2.3190 -3.3665\n",
      "  5.0425  1.8161 -0.8514 -1.4712 -4.6879\n",
      "  4.5784 -7.7308 -2.9652 -3.5952 -6.4336\n",
      " -0.8454 -7.0923  0.2370 -6.3009  6.2655\n",
      "[torch.FloatTensor of size 16x6x5x5]\n",
      ", Parameter containing:\n",
      "1.00000e-02 *\n",
      " -0.3722\n",
      " -2.4590\n",
      "  6.9044\n",
      " -2.9955\n",
      "  4.9637\n",
      "  4.5789\n",
      " -4.6468\n",
      " -4.1619\n",
      "  5.1407\n",
      "  5.8742\n",
      " -5.6969\n",
      " -1.6349\n",
      " -1.8623\n",
      "  1.5250\n",
      "  8.0152\n",
      " -3.7361\n",
      "[torch.FloatTensor of size 16]\n",
      ", Parameter containing:\n",
      "-2.7810e-02  3.8222e-02 -6.9143e-03  ...   4.7729e-02  2.1810e-02 -1.1992e-02\n",
      "-1.4445e-02  7.3317e-03 -1.0524e-03  ...   9.6658e-03 -2.6021e-02 -3.7007e-02\n",
      "-1.3108e-02 -9.1249e-03 -3.9474e-02  ...   3.6177e-02 -2.2726e-02 -2.8600e-02\n",
      "                ...                   ⋱                   ...                \n",
      "-9.7218e-03  3.2306e-02  2.9781e-02  ...  -4.3098e-03  2.8263e-02 -3.9711e-02\n",
      " 4.3460e-02 -2.7366e-02 -2.3741e-03  ...  -2.4849e-02  4.2959e-03 -2.1773e-02\n",
      " 3.2688e-02 -3.5433e-02 -2.4901e-02  ...   2.6705e-02  2.9963e-02 -1.8133e-03\n",
      "[torch.FloatTensor of size 120x400]\n",
      ", Parameter containing:\n",
      "1.00000e-02 *\n",
      "  1.2768\n",
      "  4.8863\n",
      "  0.9418\n",
      "  1.7136\n",
      " -1.0922\n",
      "  4.1373\n",
      "  4.6797\n",
      " -1.2475\n",
      "  2.9688\n",
      "  1.1101\n",
      " -0.7576\n",
      " -4.5574\n",
      "  3.9252\n",
      " -3.5486\n",
      " -4.7058\n",
      "  1.1060\n",
      " -3.3076\n",
      " -4.2003\n",
      "  3.2357\n",
      "  4.7186\n",
      "  3.6924\n",
      "  2.8447\n",
      " -2.8443\n",
      " -2.5185\n",
      "  2.4037\n",
      " -0.3578\n",
      "  1.2579\n",
      " -0.0972\n",
      "  0.4237\n",
      " -3.0104\n",
      "  1.0924\n",
      " -1.4838\n",
      " -2.5054\n",
      " -0.0384\n",
      "  0.0509\n",
      " -3.2498\n",
      "  4.2612\n",
      "  2.2977\n",
      "  4.2643\n",
      "  3.9243\n",
      " -4.8786\n",
      " -3.5873\n",
      " -4.2884\n",
      "  4.0440\n",
      " -3.8934\n",
      "  4.3256\n",
      "  4.5300\n",
      " -3.2293\n",
      " -4.0324\n",
      "  2.4703\n",
      "  2.3208\n",
      "  3.6138\n",
      " -4.4703\n",
      " -4.6362\n",
      "  4.6977\n",
      " -3.0356\n",
      " -3.6948\n",
      " -2.2569\n",
      "  3.6067\n",
      "  4.2043\n",
      "  4.1060\n",
      " -2.4723\n",
      " -1.0496\n",
      "  1.1451\n",
      " -3.1594\n",
      " -3.3016\n",
      " -2.2913\n",
      "  3.9645\n",
      " -2.1170\n",
      " -3.0104\n",
      "  1.0941\n",
      "  0.2561\n",
      "  2.9361\n",
      "  3.4197\n",
      " -2.9892\n",
      "  1.8354\n",
      "  0.3099\n",
      "  4.3191\n",
      "  4.4957\n",
      "  2.4776\n",
      " -4.3824\n",
      " -3.6844\n",
      " -2.2455\n",
      " -0.6018\n",
      "  1.6682\n",
      " -3.1459\n",
      " -1.7385\n",
      "  4.5853\n",
      "  1.3096\n",
      "  1.6235\n",
      "  1.6927\n",
      " -1.5838\n",
      " -2.0043\n",
      " -0.6338\n",
      " -0.2849\n",
      " -3.9820\n",
      " -4.2045\n",
      " -4.2761\n",
      "  1.0417\n",
      " -2.3392\n",
      "  3.2976\n",
      " -0.1208\n",
      "  1.9021\n",
      " -1.2150\n",
      " -1.1474\n",
      "  0.9203\n",
      "  3.1435\n",
      "  0.1275\n",
      " -4.5210\n",
      " -0.7952\n",
      "  4.8220\n",
      " -0.3750\n",
      " -4.8614\n",
      "  0.4740\n",
      " -3.8832\n",
      "  4.6728\n",
      " -1.8260\n",
      "  4.2105\n",
      " -2.8478\n",
      " -4.2688\n",
      "[torch.FloatTensor of size 120]\n",
      ", Parameter containing:\n",
      "1.00000e-02 *\n",
      "-1.7875  4.8601 -3.6576  ...  -6.5473  7.3154 -2.1445\n",
      "-4.1076 -3.0086 -6.2667  ...  -3.7701 -1.3493 -8.4535\n",
      " 6.2844 -3.5456 -0.4963  ...   7.9176  3.1229 -2.0042\n",
      "          ...             ⋱             ...          \n",
      " 1.0617 -2.8592  2.4396  ...   2.4398 -6.9479  5.6730\n",
      "-4.1725 -8.7780 -4.9090  ...  -8.2131 -3.8249  5.2784\n",
      " 3.0276 -3.0719 -4.9849  ...   7.5954 -0.2566 -3.3970\n",
      "[torch.FloatTensor of size 84x120]\n",
      ", Parameter containing:\n",
      "1.00000e-02 *\n",
      "  7.6268\n",
      "  6.6669\n",
      "  6.4547\n",
      " -4.1203\n",
      "  7.2425\n",
      " -1.3445\n",
      " -2.2502\n",
      " -6.2319\n",
      "  5.3830\n",
      "  8.8147\n",
      " -8.6837\n",
      "  8.3129\n",
      " -6.9442\n",
      " -0.4941\n",
      "  3.6278\n",
      " -8.6147\n",
      "  5.2210\n",
      "  4.8578\n",
      " -6.7334\n",
      " -1.1644\n",
      "  6.6202\n",
      " -6.3825\n",
      "  8.2495\n",
      "  3.3612\n",
      " -7.0813\n",
      " -5.3251\n",
      " -0.9714\n",
      "  8.8468\n",
      " -3.3292\n",
      " -0.7366\n",
      " -3.5065\n",
      "  4.2338\n",
      "  2.9751\n",
      "  3.4378\n",
      "  4.5178\n",
      " -2.6259\n",
      "  6.3117\n",
      " -0.2108\n",
      " -5.7491\n",
      " -1.3652\n",
      " -6.5018\n",
      " -5.4318\n",
      " -7.8514\n",
      " -0.1875\n",
      " -0.0305\n",
      "  2.7259\n",
      " -2.0098\n",
      "  2.8170\n",
      "  6.5138\n",
      "  8.9945\n",
      "  2.4367\n",
      "  1.8229\n",
      "  2.6755\n",
      "  5.6522\n",
      " -0.9710\n",
      " -7.0636\n",
      " -6.1630\n",
      " -0.0842\n",
      "  7.3404\n",
      " -4.9940\n",
      "  5.5816\n",
      " -4.5262\n",
      "  8.5634\n",
      " -5.0650\n",
      "  5.0910\n",
      "  4.8102\n",
      " -1.4450\n",
      "  6.3053\n",
      " -3.6377\n",
      "  7.8673\n",
      "  8.5416\n",
      "  3.4883\n",
      "  5.2948\n",
      " -8.4466\n",
      " -7.4318\n",
      "  4.4681\n",
      "  8.6398\n",
      " -0.5466\n",
      "  5.8445\n",
      " -1.4787\n",
      "  2.3189\n",
      "  7.6719\n",
      " -3.9524\n",
      " -7.6047\n",
      "[torch.FloatTensor of size 84]\n",
      ", Parameter containing:\n",
      "\n",
      "Columns 0 to 9 \n",
      "-0.0276  0.0210 -0.0078 -0.0307 -0.0741  0.0867 -0.0187 -0.0188 -0.0069 -0.0737\n",
      " 0.0747  0.0918  0.1081 -0.1005  0.0658 -0.0603  0.0972 -0.0398  0.0250 -0.1044\n",
      " 0.0012  0.0899 -0.0755  0.1050  0.0217  0.1025  0.0169  0.0724 -0.0374 -0.0914\n",
      "-0.0311 -0.0661 -0.0172 -0.0872 -0.0795  0.0359  0.1073  0.0319  0.1070 -0.0932\n",
      " 0.0831 -0.0515 -0.0106 -0.0959  0.0561 -0.0405 -0.0851  0.1005  0.0279  0.0922\n",
      "-0.1050 -0.0212  0.0947  0.0878 -0.0667 -0.0598 -0.0559  0.0288  0.0395  0.0940\n",
      " 0.1072 -0.0679 -0.0370  0.0891 -0.0744  0.0180  0.0375  0.0064 -0.0966  0.0868\n",
      " 0.0534  0.0580 -0.0797  0.0548 -0.0046  0.0522  0.0395  0.0352 -0.0995  0.0356\n",
      "-0.0395 -0.0819  0.0704 -0.0860 -0.0700  0.1086  0.0515 -0.0024 -0.1047  0.0472\n",
      " 0.0900  0.0403 -0.0271 -0.0476 -0.0880  0.0429 -0.0552  0.0315  0.0251 -0.0973\n",
      "\n",
      "Columns 10 to 19 \n",
      "-0.0681  0.0661  0.0693  0.0148  0.0288 -0.0033 -0.0268 -0.0316 -0.0712  0.0144\n",
      "-0.0823  0.0040  0.0308  0.0880 -0.0131  0.0159  0.0351 -0.0936  0.0438 -0.0552\n",
      "-0.0015 -0.0217 -0.0872  0.0091 -0.0353  0.0385  0.0514  0.0831  0.0607 -0.0434\n",
      "-0.0820 -0.0389 -0.1069  0.0143 -0.0082  0.0333  0.0990 -0.0128 -0.0375 -0.0592\n",
      "-0.1074  0.0811 -0.0712 -0.0684 -0.0345 -0.1026  0.0193 -0.0864 -0.0650 -0.0704\n",
      " 0.0030  0.0274 -0.0869  0.0253 -0.0101 -0.0674 -0.0901 -0.0905  0.0527 -0.0572\n",
      " 0.0310  0.0260 -0.0405 -0.0508  0.0554 -0.1017 -0.0607  0.0786 -0.0117  0.0082\n",
      "-0.0877 -0.0953  0.0781 -0.0463 -0.0787 -0.0084  0.0165 -0.0859  0.0070 -0.0879\n",
      " 0.0562 -0.0270 -0.0875  0.0364  0.0773  0.0702 -0.0012 -0.0084  0.0308 -0.0575\n",
      " 0.0725  0.0262  0.0362  0.0831 -0.0871  0.0062 -0.0910  0.0421 -0.0931 -0.0644\n",
      "\n",
      "Columns 20 to 29 \n",
      "-0.0583 -0.0186 -0.0940  0.0770 -0.0437  0.0198  0.0789  0.0246  0.0198  0.1085\n",
      " 0.0291 -0.0056 -0.0156  0.1036  0.0392  0.0492 -0.0633  0.0963 -0.0407  0.0680\n",
      " 0.0723  0.0222 -0.0507  0.0214 -0.0375 -0.0838 -0.0439  0.1012  0.0700 -0.0530\n",
      "-0.0087  0.0640 -0.0809  0.1073  0.0006  0.0776  0.0983  0.0635 -0.0393 -0.0648\n",
      " 0.0268 -0.0974  0.0131 -0.0932 -0.0183 -0.0072  0.0732 -0.0950 -0.0551 -0.0912\n",
      " 0.1001 -0.0150  0.0200 -0.0191  0.0042  0.0468 -0.1007  0.0346 -0.0710 -0.0044\n",
      "-0.1006  0.0667 -0.1025 -0.0849 -0.0310 -0.0155  0.0247 -0.0026 -0.0499  0.0760\n",
      " 0.0680 -0.0208 -0.0726 -0.0953  0.1028  0.1012  0.0230 -0.0548  0.0231  0.0951\n",
      " 0.0024 -0.1053  0.0409 -0.0603  0.0341  0.0071  0.0589  0.0217  0.0115 -0.0344\n",
      "-0.0258  0.0308  0.0661  0.0886 -0.0614  0.0448 -0.0763  0.0336 -0.1074 -0.0773\n",
      "\n",
      "Columns 30 to 39 \n",
      "-0.0437  0.0100 -0.1036 -0.0123  0.0300  0.0240  0.0643  0.0570  0.0748 -0.0053\n",
      " 0.0728 -0.0142 -0.0028  0.1049 -0.0985 -0.0069  0.0342 -0.0248  0.0759  0.0062\n",
      " 0.0392  0.0013 -0.0463 -0.0649  0.0436 -0.0873  0.0047 -0.0618 -0.0622 -0.0050\n",
      " 0.0209 -0.0890  0.0807 -0.0348 -0.0145 -0.0512 -0.0242 -0.1065  0.0680  0.0042\n",
      "-0.0588 -0.0683 -0.0455 -0.0133  0.1042  0.0269 -0.0314  0.0864 -0.0429 -0.0179\n",
      " 0.0880 -0.0091 -0.0970 -0.0608 -0.0269 -0.0620 -0.0403 -0.0959  0.1063 -0.0873\n",
      " 0.0891 -0.0316 -0.0060 -0.0176  0.0887 -0.1016 -0.1021 -0.0355  0.0476 -0.0174\n",
      " 0.0127 -0.1089 -0.0366  0.0223 -0.0852  0.0311  0.0611  0.0041  0.0506  0.1054\n",
      "-0.0141  0.1011 -0.0186  0.0886 -0.0270 -0.0462 -0.0433  0.0364 -0.1065  0.0421\n",
      "-0.0399 -0.0114  0.0348 -0.0306 -0.0723  0.0036 -0.0171 -0.0403 -0.0098 -0.0785\n",
      "\n",
      "Columns 40 to 49 \n",
      "-0.0017 -0.0116 -0.0000 -0.0934  0.0220 -0.0905  0.0820  0.0678  0.0366  0.0767\n",
      "-0.0024  0.0963  0.0427  0.0123 -0.0740  0.0658  0.0735 -0.0080 -0.0910  0.0770\n",
      "-0.0009  0.0457  0.0785 -0.0614  0.0073 -0.0233  0.0512 -0.0305 -0.0367 -0.0120\n",
      " 0.0569  0.0772 -0.0735 -0.1081  0.0018 -0.0633 -0.0798 -0.1017 -0.0947  0.0245\n",
      "-0.0854  0.0910  0.0844 -0.0790  0.0052  0.1060  0.0082  0.0208  0.0808 -0.0959\n",
      "-0.0002  0.0253 -0.0197 -0.0903 -0.0729  0.0983  0.0621 -0.1090 -0.0085  0.0517\n",
      " 0.0464 -0.0967  0.0928 -0.0491  0.0235  0.0619  0.0264  0.0394  0.0807  0.0929\n",
      "-0.0314  0.0374  0.0576 -0.0329  0.0759  0.0781 -0.0649 -0.0154 -0.0799  0.0647\n",
      " 0.1085 -0.0779 -0.0973  0.0576 -0.0136 -0.0653 -0.0988  0.0709 -0.0471  0.0675\n",
      " 0.0329  0.0964  0.0828 -0.1011 -0.0727  0.0283  0.0751  0.0534 -0.0022  0.0644\n",
      "\n",
      "Columns 50 to 59 \n",
      " 0.0622 -0.0911 -0.0141  0.0132 -0.0348 -0.0743  0.0952 -0.0574  0.0424  0.0547\n",
      " 0.0542  0.0587  0.0993 -0.0333 -0.0571 -0.0768  0.0409 -0.0814  0.0592 -0.0579\n",
      "-0.0037  0.0201  0.1013 -0.0830 -0.0175 -0.0973 -0.0958  0.0873 -0.0851  0.0246\n",
      "-0.0166  0.0649  0.0595 -0.0342  0.0998 -0.0032  0.0869 -0.0743 -0.0124 -0.0074\n",
      " 0.0981  0.0920 -0.0762  0.0576  0.0115 -0.0827 -0.0575  0.0611 -0.0468  0.0349\n",
      "-0.0489  0.0875 -0.0155  0.0222  0.0672  0.0384  0.0212 -0.0783  0.0766 -0.0901\n",
      " 0.0210  0.0671 -0.0976  0.0014  0.0607 -0.0970 -0.0220 -0.0736 -0.0602 -0.0517\n",
      "-0.0915  0.0162 -0.0010 -0.0631 -0.0676  0.1068  0.0299  0.0495 -0.0769 -0.0700\n",
      " 0.0227 -0.0929 -0.0141 -0.0997 -0.0885 -0.0930 -0.0879 -0.0917  0.0074  0.0404\n",
      "-0.0978  0.0598 -0.0166  0.0328 -0.0537  0.0792 -0.0406  0.0613 -0.0099  0.0064\n",
      "\n",
      "Columns 60 to 69 \n",
      "-0.0015  0.0266  0.0583  0.0932  0.0344  0.0403 -0.0357  0.0163  0.0926 -0.1087\n",
      "-0.0870  0.0372  0.1029  0.0075 -0.0163  0.0030  0.0956  0.0723  0.0234  0.0689\n",
      "-0.0178  0.0307  0.0577 -0.0164  0.0103 -0.0409 -0.0780 -0.0739 -0.0578  0.0876\n",
      "-0.0759  0.0598 -0.0811 -0.0277 -0.0244  0.0788 -0.0884 -0.0117 -0.0461 -0.0854\n",
      " 0.0645 -0.1086  0.0058 -0.0334 -0.0786 -0.0512  0.0668 -0.0598 -0.0886  0.0666\n",
      "-0.0190  0.0105 -0.0494  0.0344  0.0270  0.0718  0.0363 -0.0289 -0.0144  0.0983\n",
      " 0.0811 -0.0566  0.0985  0.0049  0.0193  0.0150 -0.0415  0.0518  0.0511  0.0541\n",
      " 0.0259 -0.1059 -0.0970  0.0546 -0.0386  0.0995  0.0635  0.0771 -0.0807 -0.0972\n",
      " 0.0997 -0.0256 -0.0315  0.1030 -0.0232 -0.0450  0.0103  0.0927  0.0342 -0.0663\n",
      " 0.0281  0.0219 -0.1026  0.0731 -0.0187  0.0660  0.0947  0.0266 -0.0359  0.0889\n",
      "\n",
      "Columns 70 to 79 \n",
      "-0.0381  0.0221 -0.0797  0.0033 -0.0072 -0.0754 -0.1075 -0.0977 -0.0812 -0.0418\n",
      "-0.0502  0.0674 -0.0778  0.1069  0.0083  0.0631 -0.1078 -0.0974 -0.0517  0.0736\n",
      "-0.0483  0.0305  0.0321 -0.0980 -0.0439  0.0552  0.0425 -0.0749 -0.0689  0.0453\n",
      " 0.0757 -0.0067  0.0167 -0.1037 -0.0638 -0.1086  0.1023  0.0953 -0.0648 -0.0931\n",
      " 0.0468 -0.0831 -0.0448 -0.0931 -0.0471 -0.0482 -0.1053 -0.0199 -0.0155 -0.0670\n",
      " 0.0313 -0.0070  0.0083  0.0473 -0.0009  0.0675 -0.0289  0.0740  0.0869 -0.0972\n",
      " 0.0542 -0.0727  0.0078  0.0882  0.0796 -0.1084  0.0851 -0.0146 -0.0860 -0.0536\n",
      "-0.0431 -0.0476  0.0341 -0.0008  0.0521 -0.0579  0.0399 -0.0358  0.0127  0.0924\n",
      "-0.0249  0.0515  0.1078  0.0312  0.0200  0.1083 -0.0288  0.0032  0.0524 -0.0773\n",
      " 0.0138 -0.0355 -0.0804  0.0396  0.0385  0.0537  0.0596 -0.0790 -0.0805 -0.0318\n",
      "\n",
      "Columns 80 to 83 \n",
      "-0.1067  0.0377  0.0286  0.0639\n",
      " 0.0208 -0.1073 -0.0785 -0.0362\n",
      "-0.0198  0.0561  0.0522  0.0205\n",
      " 0.0244 -0.0686  0.0765  0.0379\n",
      " 0.0521  0.1038  0.1036  0.0738\n",
      "-0.0201  0.1022  0.0239  0.0769\n",
      " 0.0318  0.1088  0.0842  0.1029\n",
      " 0.0836  0.0013  0.0776 -0.0248\n",
      " 0.0154  0.0354 -0.0488 -0.0064\n",
      " 0.0878 -0.0635  0.0144  0.0441\n",
      "[torch.FloatTensor of size 10x84]\n",
      ", Parameter containing:\n",
      " 0.0027\n",
      "-0.0929\n",
      "-0.0168\n",
      "-0.0127\n",
      "-0.0576\n",
      "-0.0945\n",
      " 0.0810\n",
      " 0.0023\n",
      " 0.1056\n",
      " 0.0560\n",
      "[torch.FloatTensor of size 10]\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "print(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      "1.00000e-02 *\n",
      " -7.1975 -3.9318 -2.6172 -0.5254 -6.7064 -3.9373  4.1867 -4.1266  5.4283  8.3051\n",
      "[torch.FloatTensor of size 1x10]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input = Variable(torch.randn(1, 1, 32, 32))\n",
    "out = net(input)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "net.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "out.backward(torch.randn(1, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output = net(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target = Variable(torch.arange(1, 11))\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "loss = criterion(output, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 38.4106\n",
      "[torch.FloatTensor of size 1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.autograd.function.MSELossBackward object at 0x7ff3afdfa7c8>\n"
     ]
    }
   ],
   "source": [
    "print(loss.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.autograd.function.AddmmBackward object at 0x7ff3afdfa6d8>\n",
      "<AccumulateGrad object at 0x7ff3afe7a0b8>\n"
     ]
    }
   ],
   "source": [
    "print(loss.grad_fn.next_functions[0][0])\n",
    "print(loss.grad_fn.next_functions[0][0].next_functions[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "net.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.bias.grad before backward\n",
      "Variable containing:\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      "[torch.FloatTensor of size 6]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('conv1.bias.grad before backward')\n",
    "print(net.conv1.bias.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.bias.grad after backward\n",
      "Variable containing:\n",
      " 0.0275\n",
      "-0.0402\n",
      " 0.0590\n",
      " 0.0460\n",
      "-0.0441\n",
      "-0.1042\n",
      "[torch.FloatTensor of size 6]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('conv1.bias.grad after backward')\n",
    "print(net.conv1.bias.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weight = weight - learning_rate * gradient\n",
    "learning_rate = 0.01\n",
    "for f in net.parameters():\n",
    "    f.data.sub_(f.grad.data * learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(net.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output = net(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss = criterion(output, target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
