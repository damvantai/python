{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch.autograd as autograd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fb1e4d11918>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_to_ix = {\"hello\": 0, \"world\": 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embeds = nn.Embedding(2, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding(2, 5)\n"
     ]
    }
   ],
   "source": [
    "print(embeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lookup_tensor = torch.LongTensor([word_to_ix[\"hello\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hello_embed = embeds(autograd.Variable(lookup_tensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      "-2.9718  1.7070 -0.4305 -2.2820  0.5237\n",
      "[torch.FloatTensor of size 1x5]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(hello_embed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CONTEXT_SIZE = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_sentence = \"\"\"When forty winters shall besiege thy brow,\n",
    "And dig deep trenches in thy beauty's field,\n",
    "Thy youth's proud livery so gazed on now,\n",
    "Will be a totter'd weed of small worth held:\n",
    "Then being asked, where all thy beauty lies,\n",
    "Where all the treasure of thy lusty days;\n",
    "To say, within thine own deep sunken eyes,\n",
    "Were an all-eating shame, and thriftless praise.\n",
    "How much more praise deserv'd thy beauty's use,\n",
    "If thou couldst answer 'This fair child of mine\n",
    "Shall sum my count, and make my old excuse,'\n",
    "Proving his beauty by succession thine!\n",
    "This were to be new made when thou art old,\n",
    "And see thy blood warm when thou feel'st it cold.\"\"\".split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['When', 'forty', 'winters', 'shall', 'besiege', 'thy', 'brow,', 'And', 'dig', 'deep', 'trenches', 'in', 'thy', \"beauty's\", 'field,', 'Thy', \"youth's\", 'proud', 'livery', 'so', 'gazed', 'on', 'now,', 'Will', 'be', 'a', \"totter'd\", 'weed', 'of', 'small', 'worth', 'held:', 'Then', 'being', 'asked,', 'where', 'all', 'thy', 'beauty', 'lies,', 'Where', 'all', 'the', 'treasure', 'of', 'thy', 'lusty', 'days;', 'To', 'say,', 'within', 'thine', 'own', 'deep', 'sunken', 'eyes,', 'Were', 'an', 'all-eating', 'shame,', 'and', 'thriftless', 'praise.', 'How', 'much', 'more', 'praise', \"deserv'd\", 'thy', \"beauty's\", 'use,', 'If', 'thou', 'couldst', 'answer', \"'This\", 'fair', 'child', 'of', 'mine', 'Shall', 'sum', 'my', 'count,', 'and', 'make', 'my', 'old', \"excuse,'\", 'Proving', 'his', 'beauty', 'by', 'succession', 'thine!', 'This', 'were', 'to', 'be', 'new', 'made', 'when', 'thou', 'art', 'old,', 'And', 'see', 'thy', 'blood', 'warm', 'when', 'thou', \"feel'st\", 'it', 'cold.']\n"
     ]
    }
   ],
   "source": [
    "print(test_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "115\n"
     ]
    }
   ],
   "source": [
    "print(len(test_sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trigrams = [([test_sentence[i], test_sentence[i + 1]], test_sentence[i + 2]) for i in range(len(test_sentence) - 2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(['When', 'forty'], 'winters'), (['forty', 'winters'], 'shall'), (['winters', 'shall'], 'besiege')]\n"
     ]
    }
   ],
   "source": [
    "print(trigrams[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab = set(test_sentence)\n",
    "word_to_ix ={word: i for i, word in enumerate(vocab)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dig', 'Then', 'use,', 'child', 'thy', 'old,', 'succession', 'shame,', 'beauty', 'my', 'lies,', 'forty', 'mine', 'on', 'when', 'Thy', 'see', 'days;', 'to', 'all', 'say,', 'sum', 'praise', \"youth's\", 'Proving', 'it', 'deep', 'small', 'Where', 'in', 'own', 'worth', 'lusty', 'more', 'If', 'trenches', 'asked,', 'by', \"beauty's\", 'gazed', 'weed', 'winters', 'praise.', 'fair', 'his', \"feel'st\", 'Were', 'eyes,', 'count,', 'When', 'being', 'thriftless', 'and', 'To', 'besiege', 'make', 'Shall', 'where', 'Will', 'so', 'new', 'livery', 'thine', 'And', 'an', 'all-eating', 'answer', 'the', 'within', 'couldst', 'art', 'sunken', \"totter'd\", 'How', \"excuse,'\", 'thou', 'treasure', 'This', 'thine!', 'of', \"'This\", 'warm', 'field,', 'shall', 'proud', 'held:', 'blood', 'much', 'now,', 'made', 'brow,', 'be', 'a', \"deserv'd\", 'were', 'old', 'cold.'}\n"
     ]
    }
   ],
   "source": [
    "print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dig': 0, 'eyes,': 47, 'Then': 1, 'use,': 2, 'so': 59, 'child': 3, 'shame,': 7, 'count,': 48, 'thy': 4, 'lusty': 32, 'When': 49, 'old,': 5, 'How': 73, 'it': 25, 'succession': 6, 'being': 50, 'thriftless': 51, 'beauty': 8, 'my': 9, 'and': 52, 'To': 53, 'besiege': 54, 'make': 55, 'lies,': 10, 'sum': 21, 'Shall': 56, 'forty': 11, 'where': 57, 'mine': 12, 'on': 13, 'Will': 58, 'new': 60, 'Thy': 15, 'livery': 61, 'see': 16, 'thine': 62, 'days;': 17, 'And': 63, 'an': 64, 'to': 18, 'answer': 66, 'say,': 20, 'the': 67, 'by': 37, 'within': 68, 'praise': 22, 'art': 70, 'sunken': 71, \"totter'd\": 72, 'all': 19, \"youth's\": 23, 'Proving': 24, 'deep': 26, 'his': 44, \"excuse,'\": 74, 'thou': 75, 'Where': 28, 'small': 27, 'treasure': 76, 'This': 77, 'in': 29, 'thine!': 78, 'of': 79, 'worth': 31, \"deserv'd\": 93, \"'This\": 80, 'warm': 81, 'more': 33, 'field,': 82, 'couldst': 69, 'If': 34, 'trenches': 35, 'asked,': 36, 'when': 14, 'shall': 83, 'proud': 84, 'held:': 85, \"beauty's\": 38, 'blood': 86, 'gazed': 39, 'much': 87, 'winters': 41, 'own': 30, 'praise.': 42, 'now,': 88, 'old': 95, 'all-eating': 65, 'weed': 40, 'fair': 43, 'brow,': 90, 'be': 91, 'a': 92, \"feel'st\": 45, 'Were': 46, 'were': 94, 'made': 89, 'cold.': 96}\n",
      "97\n"
     ]
    }
   ],
   "source": [
    "print(word_to_ix)\n",
    "print(len(word_to_ix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n"
     ]
    }
   ],
   "source": [
    "for i, word in enumerate(vocab):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class NGramLanguageModeler(nn.Module):\n",
    "    \n",
    "    def __init__(self, vocab_size, embedding_dim, context_size):\n",
    "        super(NGramLanguageModeler, self).__init__()\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.linear1 = nn.Linear(context_size * embedding_dim, 128)\n",
    "        self.linear2 = nn.Linear(128, vocab_size)\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        embeds = self.embeddings(inputs).view((1, -1))\n",
    "        out = F.relu(self.linear1(embeds))\n",
    "        out = self.linear2(out)\n",
    "        log_probs = F.log_softmax(out)\n",
    "        return log_probs\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss_function = nn.NLLLoss()\n",
    "model = NGramLanguageModeler(len(vocab), EMBEDDING_DIM, CONTEXT_SIZE)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      " 516.2596\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 513.8099\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 511.3762\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 508.9582\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 506.5530\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 504.1596\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 501.7760\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 499.4015\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 497.0373\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 494.6816\n",
      "[torch.FloatTensor of size 1]\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10):\n",
    "    total_loss = torch.Tensor([0])\n",
    "    for context, target in trigrams:\n",
    "        \n",
    "        context_idxs = [word_to_ix[w] for w in context]\n",
    "        context_var = autograd.Variable(torch.LongTensor(context_idxs))\n",
    "        \n",
    "        model.zero_grad()\n",
    "        \n",
    "        log_probs = model(context_var)\n",
    "        \n",
    "#         loss = loss_function(log_probs, autograd.Variable(torch.LongTensor[word_to_ix[target]]))\n",
    "        loss = loss_function(log_probs, autograd.Variable(torch.LongTensor([word_to_ix[target]])))    \n",
    "    \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.data\n",
    "    losses.append(total_loss)\n",
    "print(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
